{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d84809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.container import Sequential\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7e66f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56cac7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    dataPath = \"./open/\"\n",
    "    trainPath = dataPath+'train.csv'\n",
    "    testPath = dataPath+'test.csv'\n",
    "    submission = dataPath+'sample_submission.csv'\n",
    "    outPath = './output/'\n",
    "    weightsavePath = './weights/'\n",
    "    device = device\n",
    "\n",
    "    batch_size = 1024\n",
    "    lr = 0.0001\n",
    "    epochs = 5\n",
    "#     warmup_num\n",
    "    decay = 0.00001\n",
    "    num_depth = 300\n",
    "    num_hidden_node = 512\n",
    "\n",
    "\n",
    "config_data = {\n",
    "    'epochs': CFG.epochs,\n",
    "    'num_depth': CFG.num_depth,\n",
    "    'num_hidden_node': CFG.num_hidden_node,\n",
    "    'lr': CFG.lr,\n",
    "    'decay': CFG.decay,\n",
    "    'batch_size': CFG.batch_size\n",
    "}\n",
    "\n",
    "pbounds = {'epoch': (50, 500),\n",
    "           'num_depth': (50, 400),\n",
    "           'num_hidden_node': (124, 512),\n",
    "           'lr': (0.00001, 0.007),\n",
    "           'decay': (0.00001, 0.001),\n",
    "           'batch_size': (512, 1024)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc99c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seedEverything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "#     torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561f5a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "data_df = pd.read_csv(CFG.trainPath)\n",
    "test_df = pd.read_csv(CFG.testPath)\n",
    "train_df, val_df = train_test_split(data_df, test_size=0.1)\n",
    "\n",
    "# valset_ratio = 0.15\n",
    "# train_df = train_df.sample(frac=1)\n",
    "\n",
    "\n",
    "def numpy2tensor(variable):\n",
    "    x = variable.values\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "# TODO normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e73bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(56, CFG.num_hidden_node)\n",
    "        self.norm1 = nn.BatchNorm1d(CFG.num_hidden_node)\n",
    "        self.layer1 = self.make_layers(\n",
    "            CFG.num_hidden_node, num_repeat=CFG.num_depth)\n",
    "\n",
    "        self.fc2 = nn.Linear(CFG.num_hidden_node, 1024)\n",
    "        self.norm2 = nn.BatchNorm1d(1024)\n",
    "        self.LeakyReLU = nn.LeakyReLU(inplace=True)\n",
    "        self.fc3 = nn.Linear(1024, 14)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.norm1(x)\n",
    "#         x = nn.BatchNorm1d(128)(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = nn.Dropout(0.3)(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, value, num_repeat):\n",
    "        layers = []\n",
    "        for _ in range(num_repeat):\n",
    "            layers.append(nn.Linear(value, value))\n",
    "            layers.append(nn.BatchNorm1d(value))\n",
    "            layers.append(nn.LeakyReLU(inplace=True))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "# TODO find opt param with basyan, skip connection, warmup, shuffle, smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f24a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "\n",
    "\n",
    "def train(model, epochs, device, criterion, optimizer, loader_train, loader_valid, scheduler=None):\n",
    "    model.to(device)\n",
    "    best_score = 100000\n",
    "    train_x = numpy2tensor(loader_train.filter(regex='X'))\n",
    "    train_y = numpy2tensor(loader_train.filter(regex='Y'))\n",
    "    iter_num = int(np.ceil(len(train_x)/CFG.batch_size))\n",
    "    total_loss = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for i in range(iter_num):\n",
    "            start = i * CFG.batch_size\n",
    "            end = start + CFG.batch_size\n",
    "            input = train_x[start:end].to(device, dtype=torch.float)\n",
    "            label = train_y[start:end].to(device, dtype=torch.float)\n",
    "            outputs = model(input)\n",
    "            loss = criterion(outputs, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(\n",
    "            f' epoch : {epoch+1}/{epochs}, train loss : {(epoch_loss/iter_num):.4f}')\n",
    "#         print(f' epoch : {epoch+1}/{epochs}, train loss : {epoch_loss}')\n",
    "        loss = val(model, loader_valid, criterion, device)\n",
    "        total_loss += loss\n",
    "        if best_score > loss:\n",
    "            best_score = loss\n",
    "            torch.save(model.state_dict(), CFG.weightsavePath+'best_model.pth')\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def val(model, loader_valid, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_x = numpy2tensor(loader_valid.filter(regex='X'))\n",
    "    val_y = numpy2tensor(loader_valid.filter(regex='Y'))\n",
    "    iter_num = int(np.ceil(len(val_x)/CFG.batch_size))\n",
    "    true_list = []\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(iter_num):\n",
    "            start = i * CFG.batch_size\n",
    "            end = start + CFG.batch_size\n",
    "            input = val_x[start:end].to(device, dtype=torch.float)\n",
    "            label = val_y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "            preds = model(input).squeeze()\n",
    "            loss = criterion(preds, label)\n",
    "            val_loss += loss.item()\n",
    "#             print(preds.cpu().numpy())\n",
    "            preds_list.extend(preds.cpu().numpy())\n",
    "            true_list.extend(label.cpu().numpy())\n",
    "        print(f'  val loss : {(val_loss/iter_num):.4f}')\n",
    "        return r2_score()\n",
    "    # todo : 함수 매게변수랑 베이지안 변수랑 동일하게,consin, 앙상블 regression모델, 피쳐인코\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b39d470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seedEverything(0)\n",
    "\n",
    "model = myModel()\n",
    "# print(model)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.0001)\n",
    "# scheduler = get_cosine_schedule_with_warmup(optimizer,num_warmup_steps=len(train_df)*CFG.warmup_num,num_training_steps=len(train_df)*CFG.epochs)\n",
    "criterion = nn.L1Loss().cuda()\n",
    "\n",
    "\n",
    "# TODO enanble (ML and DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29befb21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch : 1/5, train loss : 17.5838\n",
      "  val loss : 17.5587\n",
      " epoch : 2/5, train loss : 17.5560\n",
      "  val loss : 17.5585\n",
      " epoch : 3/5, train loss : 17.5560\n",
      "  val loss : 17.5585\n",
      " epoch : 4/5, train loss : 17.5561\n",
      "  val loss : 17.5587\n",
      " epoch : 5/5, train loss : 17.5559\n",
      "  val loss : 17.5587\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "bO = BayesianOptimization(f=train(model, CFG.epochs, CFG.device, criterion,\n",
    "                          optimizer, train_df, val_df), pbounds=pbounds, verbose=2, random_state=1)\n",
    "# bo.minimize(init_points=5, n_iter=20,)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 앙상블(deep , and ml, smoothing, skip connection, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "256bb311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |   decay   |   epoch   |    lr     | num_depth | num_hi... |\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (725.515266407718, 0.0007231212485077365, 50.051468667805196, 0.00212330468269656, 101.36456178598957, 159.82737477029355)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17881/4009572596.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "bO.maximize(init_points=5, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff768bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bo.max)\n",
    "# print(bo.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = int(np.ceil(len(test_df)/CFG.batch_size))\n",
    "test_loader = numpy2tensor(test_df.filter(regex='X'))\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(CFG.batch_size):\n",
    "        start = i * CFG.batch_size\n",
    "        end = start + CFG.batch_size\n",
    "\n",
    "        input = test_loader[start:end].to(device, dtype=torch.float)\n",
    "        input = input.to(device)\n",
    "        outputs = model(input).squeeze()\n",
    "        preds += outputs.detach().cpu().numpy().tolist()\n",
    "# print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654de0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np = np.array(preds)\n",
    "preds_np.shape\n",
    "print(preds_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecf038",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(CFG.submission)\n",
    "submission_df.iloc[:, 1:] = preds\n",
    "submission_df.to_csv('./submit_rev2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41066d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
