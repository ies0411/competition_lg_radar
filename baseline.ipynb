{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44a4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.container import Sequential\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7a32f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7431e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    dataPath = \"./open/\"\n",
    "    trainPath = dataPath+'train.csv'\n",
    "    testPath = dataPath+'test.csv'\n",
    "    submission = dataPath+'sample_submission.csv'\n",
    "    outPath = './output/'\n",
    "    weightsavePath = './weights/'\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3f3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seedEverything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "#     torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    np.random.seed(random_seed)    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d4016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_df = pd.read_csv(CFG.trainPath)\n",
    "train_df, val_df = train_test_split(data_df,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c112ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def numpy_to_tensor(variable):\n",
    "    x = variable.values\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, is_test=False):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        label = self.df.filter(regex='Y')\n",
    "        input_data = self.df.filter(regex='X')\n",
    "        if is_test == True:\n",
    "            return numpy_to_tensor(input_data)\n",
    "        return numpy_to_tensor(input_data), numpy_to_tensor(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb6debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_set = CustomDataset(df=train_df)\n",
    "val_set = CustomDataset(df=val_df)\n",
    "\n",
    "loader_train = DataLoader(dataset=train_set,batch_size=1024,shuffle=True)\n",
    "loader_val = DataLoader(dataset=val_set,batch_size=1024,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72a67b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(56, 512)\n",
    "        self.layer1 = self.make_layers(512, num_repeat=300)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc5 = nn.Linear(512, 14)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Dropout(0.2)(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, value, num_repeat):\n",
    "        layers = []\n",
    "        for _ in range(num_repeat):\n",
    "            layers.append(nn.Linear(value, value))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_batch, criterion, optimizer, train_X, train_Y, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i in range(train_batch):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        input = train_X[start:end].to(device, dtype=torch.float)\n",
    "        label = train_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        outputs = model(input).squeeze()\n",
    "        loss = criterion(outputs, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f\"train_loss : {train_loss}\")\n",
    "    \n",
    "def val_one_epoch(model, val_batch, criterion, val_X, val_Y, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i in range(val_batch):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            input = val_X[start:end].to(device, dtype=torch.float)\n",
    "            label = val_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "            input, label = input.to(device), label.to(device)\n",
    "            outputs = model(input).squeeze()\n",
    "            loss = criterion(outputs, label)\n",
    "            val_loss += loss.item()\n",
    "    print(f\"val_loss : {val_loss}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef91e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456b6d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_04</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>X_10</th>\n",
       "      <th>...</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "      <th>X_51</th>\n",
       "      <th>X_52</th>\n",
       "      <th>X_53</th>\n",
       "      <th>X_54</th>\n",
       "      <th>X_55</th>\n",
       "      <th>X_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.504</td>\n",
       "      <td>103.321</td>\n",
       "      <td>76.67</td>\n",
       "      <td>1</td>\n",
       "      <td>101.867</td>\n",
       "      <td>73.963</td>\n",
       "      <td>30.51</td>\n",
       "      <td>63.57</td>\n",
       "      <td>239.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17227.63</td>\n",
       "      <td>138.130429</td>\n",
       "      <td>129.460682</td>\n",
       "      <td>141.506570</td>\n",
       "      <td>133.427229</td>\n",
       "      <td>129.711498</td>\n",
       "      <td>133.138096</td>\n",
       "      <td>121.859684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.485</td>\n",
       "      <td>103.320</td>\n",
       "      <td>69.37</td>\n",
       "      <td>1</td>\n",
       "      <td>101.992</td>\n",
       "      <td>67.845</td>\n",
       "      <td>28.03</td>\n",
       "      <td>116.99</td>\n",
       "      <td>189.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17134.53</td>\n",
       "      <td>136.148839</td>\n",
       "      <td>128.266277</td>\n",
       "      <td>145.911745</td>\n",
       "      <td>131.196417</td>\n",
       "      <td>132.411480</td>\n",
       "      <td>133.629025</td>\n",
       "      <td>124.178623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>68.97</td>\n",
       "      <td>1</td>\n",
       "      <td>101.884</td>\n",
       "      <td>77.022</td>\n",
       "      <td>29.65</td>\n",
       "      <td>205.68</td>\n",
       "      <td>214.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14860.83</td>\n",
       "      <td>120.447446</td>\n",
       "      <td>119.988804</td>\n",
       "      <td>132.099908</td>\n",
       "      <td>120.450155</td>\n",
       "      <td>130.051708</td>\n",
       "      <td>128.252972</td>\n",
       "      <td>114.475628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>65.87</td>\n",
       "      <td>1</td>\n",
       "      <td>101.866</td>\n",
       "      <td>73.963</td>\n",
       "      <td>28.15</td>\n",
       "      <td>103.38</td>\n",
       "      <td>180.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15252.53</td>\n",
       "      <td>133.994695</td>\n",
       "      <td>125.069180</td>\n",
       "      <td>147.507669</td>\n",
       "      <td>123.142653</td>\n",
       "      <td>125.963665</td>\n",
       "      <td>139.666592</td>\n",
       "      <td>126.589253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.603</td>\n",
       "      <td>103.321</td>\n",
       "      <td>66.67</td>\n",
       "      <td>1</td>\n",
       "      <td>101.891</td>\n",
       "      <td>74.983</td>\n",
       "      <td>29.92</td>\n",
       "      <td>71.20</td>\n",
       "      <td>231.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10752.23</td>\n",
       "      <td>137.918202</td>\n",
       "      <td>135.116192</td>\n",
       "      <td>138.600473</td>\n",
       "      <td>127.173033</td>\n",
       "      <td>137.252712</td>\n",
       "      <td>134.411335</td>\n",
       "      <td>124.020016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39603</th>\n",
       "      <td>68.504</td>\n",
       "      <td>103.320</td>\n",
       "      <td>63.97</td>\n",
       "      <td>1</td>\n",
       "      <td>103.157</td>\n",
       "      <td>68.864</td>\n",
       "      <td>29.49</td>\n",
       "      <td>116.35</td>\n",
       "      <td>284.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62123.53</td>\n",
       "      <td>127.741246</td>\n",
       "      <td>126.494312</td>\n",
       "      <td>139.119905</td>\n",
       "      <td>125.271109</td>\n",
       "      <td>128.284572</td>\n",
       "      <td>140.176945</td>\n",
       "      <td>128.292843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39604</th>\n",
       "      <td>68.504</td>\n",
       "      <td>103.320</td>\n",
       "      <td>61.37</td>\n",
       "      <td>1</td>\n",
       "      <td>103.137</td>\n",
       "      <td>68.864</td>\n",
       "      <td>32.29</td>\n",
       "      <td>116.28</td>\n",
       "      <td>272.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61844.13</td>\n",
       "      <td>127.767377</td>\n",
       "      <td>124.062809</td>\n",
       "      <td>138.238664</td>\n",
       "      <td>119.879393</td>\n",
       "      <td>127.322529</td>\n",
       "      <td>137.312047</td>\n",
       "      <td>131.570614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39605</th>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>63.67</td>\n",
       "      <td>1</td>\n",
       "      <td>103.149</td>\n",
       "      <td>69.884</td>\n",
       "      <td>30.00</td>\n",
       "      <td>113.05</td>\n",
       "      <td>295.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60277.53</td>\n",
       "      <td>128.593640</td>\n",
       "      <td>124.774037</td>\n",
       "      <td>138.659624</td>\n",
       "      <td>123.999571</td>\n",
       "      <td>126.075542</td>\n",
       "      <td>135.656132</td>\n",
       "      <td>127.671108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39606</th>\n",
       "      <td>67.485</td>\n",
       "      <td>103.321</td>\n",
       "      <td>61.77</td>\n",
       "      <td>1</td>\n",
       "      <td>103.148</td>\n",
       "      <td>67.845</td>\n",
       "      <td>32.05</td>\n",
       "      <td>115.05</td>\n",
       "      <td>267.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60236.73</td>\n",
       "      <td>121.110646</td>\n",
       "      <td>125.471699</td>\n",
       "      <td>134.989984</td>\n",
       "      <td>120.889578</td>\n",
       "      <td>129.296909</td>\n",
       "      <td>132.673977</td>\n",
       "      <td>131.882893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39607</th>\n",
       "      <td>71.563</td>\n",
       "      <td>103.320</td>\n",
       "      <td>63.07</td>\n",
       "      <td>1</td>\n",
       "      <td>103.158</td>\n",
       "      <td>71.923</td>\n",
       "      <td>31.14</td>\n",
       "      <td>102.22</td>\n",
       "      <td>215.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60680.73</td>\n",
       "      <td>134.263593</td>\n",
       "      <td>129.765515</td>\n",
       "      <td>139.681833</td>\n",
       "      <td>128.243391</td>\n",
       "      <td>131.757923</td>\n",
       "      <td>139.903401</td>\n",
       "      <td>121.479191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39608 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08    X_09  \\\n",
       "0      68.504  103.321  76.67     1  101.867  73.963  30.51   63.57  239.80   \n",
       "1      67.485  103.320  69.37     1  101.992  67.845  28.03  116.99  189.23   \n",
       "2      69.524  103.320  68.97     1  101.884  77.022  29.65  205.68  214.93   \n",
       "3      69.524  103.320  65.87     1  101.866  73.963  28.15  103.38  180.80   \n",
       "4      73.603  103.321  66.67     1  101.891  74.983  29.92   71.20  231.93   \n",
       "...       ...      ...    ...   ...      ...     ...    ...     ...     ...   \n",
       "39603  68.504  103.320  63.97     1  103.157  68.864  29.49  116.35  284.16   \n",
       "39604  68.504  103.320  61.37     1  103.137  68.864  32.29  116.28  272.41   \n",
       "39605  69.524  103.320  63.67     1  103.149  69.884  30.00  113.05  295.54   \n",
       "39606  67.485  103.321  61.77     1  103.148  67.845  32.05  115.05  267.26   \n",
       "39607  71.563  103.320  63.07     1  103.158  71.923  31.14  102.22  215.85   \n",
       "\n",
       "       X_10  ...  X_47  X_48      X_49        X_50        X_51        X_52  \\\n",
       "0       0.0  ...     1     1  17227.63  138.130429  129.460682  141.506570   \n",
       "1       0.0  ...     1     1  17134.53  136.148839  128.266277  145.911745   \n",
       "2       0.0  ...     1     1  14860.83  120.447446  119.988804  132.099908   \n",
       "3       0.0  ...     1     1  15252.53  133.994695  125.069180  147.507669   \n",
       "4       0.0  ...     1     1  10752.23  137.918202  135.116192  138.600473   \n",
       "...     ...  ...   ...   ...       ...         ...         ...         ...   \n",
       "39603   0.0  ...     1     1  62123.53  127.741246  126.494312  139.119905   \n",
       "39604   0.0  ...     1     1  61844.13  127.767377  124.062809  138.238664   \n",
       "39605   0.0  ...     1     1  60277.53  128.593640  124.774037  138.659624   \n",
       "39606   0.0  ...     1     1  60236.73  121.110646  125.471699  134.989984   \n",
       "39607   0.0  ...     1     1  60680.73  134.263593  129.765515  139.681833   \n",
       "\n",
       "             X_53        X_54        X_55        X_56  \n",
       "0      133.427229  129.711498  133.138096  121.859684  \n",
       "1      131.196417  132.411480  133.629025  124.178623  \n",
       "2      120.450155  130.051708  128.252972  114.475628  \n",
       "3      123.142653  125.963665  139.666592  126.589253  \n",
       "4      127.173033  137.252712  134.411335  124.020016  \n",
       "...           ...         ...         ...         ...  \n",
       "39603  125.271109  128.284572  140.176945  128.292843  \n",
       "39604  119.879393  127.322529  137.312047  131.570614  \n",
       "39605  123.999571  126.075542  135.656132  127.671108  \n",
       "39606  120.889578  129.296909  132.673977  131.882893  \n",
       "39607  128.243391  131.757923  139.903401  121.479191  \n",
       "\n",
       "[39608 rows x 56 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(CFG.testPath)\n",
    "test_df_XX = test_df.filter(regex='X')\n",
    "# test_df_X = pandas_to_tensor(test_df.iloc[:])\n",
    "test_df_XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deaad83e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas_to_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2215412/950834199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df_XX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas_to_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = pandas_to_tensor(test_df_XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    seedEverything(42)\n",
    "    train_df = pd.read_csv(CFG.trainPath)    \n",
    "    train_df_X, train_df_Y, val_df_X, val_df_Y = datapreparation(train_df)\n",
    "\n",
    "    model = NeuralNet()\n",
    "    model = model.to(CFG.device)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=3e-4)\n",
    "    criterion = nn.L1Loss().cuda()\n",
    "\n",
    "    num_epochs = 300\n",
    "    batch_size = 2048\n",
    "    \n",
    "    train_batch = len(train_df_X) // batch_size\n",
    "    val_batch = len(val_df_X) // batch_size\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"epoch:{epoch}\")\n",
    "        train_one_epoch(model, train_batch, criterion, optimizer, train_df_X, train_df_Y, CFG.device)\n",
    "        val_one_epoch(model, val_batch, criterion, val_df_X, val_df_Y, CFG.device)\n",
    "        # gc.collect()\n",
    "        torch.save(model.state_dict(), CFG.weightsavePath+f'{epoch}_neuralnet.pt')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdcf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, test_loader, device):\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "#     model_preds = []\n",
    "#     with torch.no_grad():\n",
    "#         for data in tqdm(iter(test_loader)):\n",
    "#             data = data.float().to(device)\n",
    "            \n",
    "#             batch_pred = model(data)\n",
    "            \n",
    "#             model_preds += batch_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "#     return model_preds\n",
    "\n",
    "test_batch = len(test_df_XX) // batch_size\n",
    "model.eval()\n",
    "preds=[]\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    for i in range(test_batch+1):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        print(end)\n",
    "        if end>len(test_data):\n",
    "#             print(\"check\")\n",
    "            end = len(test_data)\n",
    "            \n",
    "        input = test_data[start:end].to(device, dtype=torch.float)\n",
    "#         label = val_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "        input= input.to(device)\n",
    "        outputs = model(input).squeeze()\n",
    "#         print(outputs)\n",
    "        preds += outputs.detach().cpu().numpy().tolist()\n",
    "#         preds.append(outputs\n",
    "#         loss = criterion(outputs, label)\n",
    "#         val_loss += loss.item()\n",
    "# print(f\"val_loss : {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc008d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds\n",
    "preds_np=np.array(preds)\n",
    "preds_np.shape\n",
    "\n",
    "# preds_np = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e156886",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(CFG.submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f282bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7337c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a90162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(n_models):\n",
    "  all_models=list()\n",
    "  for i in range(n_models):\n",
    "    filename='/content/drive/MyDrive/lg aimers/models/'+str(i+1)+'.h5'\n",
    "    model=load_model(filename)\n",
    "    all_models.append(model)\n",
    "\n",
    "    print('>loaded %s' %filename)\n",
    "  return all_models\n",
    "  \n",
    "def define_stacked_model(members):\n",
    "  # update all layers in all models to not be trainiable\n",
    "  for i in range(len(members)):\n",
    "    model=members[i]\n",
    "    for layer in model.layers:\n",
    "      layer.trainable=False\n",
    "      # rename to avoid 'unique layer name' issue\n",
    "      layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "  \n",
    "  # define multi-handed input\n",
    "  ensemble_visible=[model.input for model in members]\n",
    "  ensemble_outputs=[model.output for model in members]\n",
    "\n",
    "  y=Average()(ensemble_outputs)\n",
    "\n",
    "  model=Model(inputs=ensemble_visible,outputs=y,name='ensemble')\n",
    "\n",
    "  keras.utils.plot_model(model,show_shapes=True,to_file='/content/drive/MyDrive/lg aimers/model_graph.jpg')\n",
    "\n",
    "  model.compile(loss='mae',optimizer='adam')\n",
    "  return model\n",
    "\n",
    "def fit_stacked_model(model,trainX,valX,trainY,valY):\n",
    "  x_train=[trainX for _ in range(len(model.input))]\n",
    "  x_val=[valX for _ in range(len(model.input))]\n",
    "  y_train=trainY\n",
    "  y_val=valY\n",
    "\n",
    "  es=keras.callbacks.EarlyStopping(monitor='val_loss',patience=20)\n",
    "  checkpoint_filepath='/content/drive/MyDrive/lg aimers/ensemble_model.h5'\n",
    "  cp=keras.callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      monitor='val_loss',\n",
    "      save_best_only=True\n",
    "  )\n",
    "  model.fit(x_train,y_train,epochs=1,validation_data=(x_val,y_val),callbacks=[es,cp],batch_size=32)\n",
    "\n",
    "def evaluate_stacked_model(model,inputX,y_val):\n",
    "  x_val=[inputX for _ in range(len(model.input))]\n",
    "  return model.evaluate(x_val,y_val)\n",
    "\n",
    "def predict_stacked_model(model,inputX):\n",
    "  x_test=[inputX for _ in range(len(model.input))]\n",
    "  return model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95183fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_members=5\n",
    "members=load_all_models(n_members)\n",
    "print('Loaded %d members' %len(members))\n",
    "\n",
    "stacked_model=define_stacked_model(members)\n",
    "fit_stacked_model(stacked_model,x_train,x_val,y_train,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_stacked_model(stacked_model,x_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=predict_stacked_model(stacked_model,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e733fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pd=pd.read_csv('/content/drive/MyDrive/lg aimers/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf812a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,col in enumerate(submission_pd.columns):\n",
    "  if col=='ID':\n",
    "    continue\n",
    "  submission_pd[col]=result[:,idx-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pd.to_csv('/content/drive/MyDrive/lg aimers/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
