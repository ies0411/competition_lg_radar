{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44a4691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=56, out_features=512, bias=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (21): ReLU(inplace=True)\n",
      "    (22): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (23): ReLU(inplace=True)\n",
      "    (24): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (37): ReLU(inplace=True)\n",
      "    (38): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (43): ReLU(inplace=True)\n",
      "    (44): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (47): ReLU(inplace=True)\n",
      "    (48): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (49): ReLU(inplace=True)\n",
      "    (50): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (53): ReLU(inplace=True)\n",
      "    (54): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (55): ReLU(inplace=True)\n",
      "    (56): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (57): ReLU(inplace=True)\n",
      "    (58): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (59): ReLU(inplace=True)\n",
      "    (60): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (61): ReLU(inplace=True)\n",
      "    (62): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (63): ReLU(inplace=True)\n",
      "    (64): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (65): ReLU(inplace=True)\n",
      "    (66): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (67): ReLU(inplace=True)\n",
      "    (68): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (69): ReLU(inplace=True)\n",
      "    (70): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (71): ReLU(inplace=True)\n",
      "    (72): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (73): ReLU(inplace=True)\n",
      "    (74): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (75): ReLU(inplace=True)\n",
      "    (76): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (77): ReLU(inplace=True)\n",
      "    (78): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (79): ReLU(inplace=True)\n",
      "    (80): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (81): ReLU(inplace=True)\n",
      "    (82): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (83): ReLU(inplace=True)\n",
      "    (84): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (85): ReLU(inplace=True)\n",
      "    (86): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (87): ReLU(inplace=True)\n",
      "    (88): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (89): ReLU(inplace=True)\n",
      "    (90): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (91): ReLU(inplace=True)\n",
      "    (92): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (93): ReLU(inplace=True)\n",
      "    (94): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (95): ReLU(inplace=True)\n",
      "    (96): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (97): ReLU(inplace=True)\n",
      "    (98): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (99): ReLU(inplace=True)\n",
      "    (100): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (101): ReLU(inplace=True)\n",
      "    (102): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (103): ReLU(inplace=True)\n",
      "    (104): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (105): ReLU(inplace=True)\n",
      "    (106): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (107): ReLU(inplace=True)\n",
      "    (108): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (109): ReLU(inplace=True)\n",
      "    (110): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (111): ReLU(inplace=True)\n",
      "    (112): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (113): ReLU(inplace=True)\n",
      "    (114): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (115): ReLU(inplace=True)\n",
      "    (116): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (117): ReLU(inplace=True)\n",
      "    (118): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (119): ReLU(inplace=True)\n",
      "    (120): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (121): ReLU(inplace=True)\n",
      "    (122): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (123): ReLU(inplace=True)\n",
      "    (124): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (125): ReLU(inplace=True)\n",
      "    (126): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (127): ReLU(inplace=True)\n",
      "    (128): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (129): ReLU(inplace=True)\n",
      "    (130): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (131): ReLU(inplace=True)\n",
      "    (132): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (133): ReLU(inplace=True)\n",
      "    (134): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (135): ReLU(inplace=True)\n",
      "    (136): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (137): ReLU(inplace=True)\n",
      "    (138): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (139): ReLU(inplace=True)\n",
      "    (140): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (141): ReLU(inplace=True)\n",
      "    (142): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (143): ReLU(inplace=True)\n",
      "    (144): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (145): ReLU(inplace=True)\n",
      "    (146): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (147): ReLU(inplace=True)\n",
      "    (148): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (149): ReLU(inplace=True)\n",
      "    (150): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (151): ReLU(inplace=True)\n",
      "    (152): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (153): ReLU(inplace=True)\n",
      "    (154): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (155): ReLU(inplace=True)\n",
      "    (156): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (157): ReLU(inplace=True)\n",
      "    (158): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (159): ReLU(inplace=True)\n",
      "    (160): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (161): ReLU(inplace=True)\n",
      "    (162): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (163): ReLU(inplace=True)\n",
      "    (164): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (165): ReLU(inplace=True)\n",
      "    (166): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (167): ReLU(inplace=True)\n",
      "    (168): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (169): ReLU(inplace=True)\n",
      "    (170): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (171): ReLU(inplace=True)\n",
      "    (172): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (173): ReLU(inplace=True)\n",
      "    (174): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (175): ReLU(inplace=True)\n",
      "    (176): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (177): ReLU(inplace=True)\n",
      "    (178): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (179): ReLU(inplace=True)\n",
      "    (180): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (181): ReLU(inplace=True)\n",
      "    (182): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (183): ReLU(inplace=True)\n",
      "    (184): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (185): ReLU(inplace=True)\n",
      "    (186): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (187): ReLU(inplace=True)\n",
      "    (188): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (189): ReLU(inplace=True)\n",
      "    (190): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (191): ReLU(inplace=True)\n",
      "    (192): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (193): ReLU(inplace=True)\n",
      "    (194): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (195): ReLU(inplace=True)\n",
      "    (196): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (197): ReLU(inplace=True)\n",
      "    (198): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (199): ReLU(inplace=True)\n",
      "    (200): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (201): ReLU(inplace=True)\n",
      "    (202): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (203): ReLU(inplace=True)\n",
      "    (204): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (205): ReLU(inplace=True)\n",
      "    (206): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (207): ReLU(inplace=True)\n",
      "    (208): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (209): ReLU(inplace=True)\n",
      "    (210): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (211): ReLU(inplace=True)\n",
      "    (212): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (213): ReLU(inplace=True)\n",
      "    (214): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (215): ReLU(inplace=True)\n",
      "    (216): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (217): ReLU(inplace=True)\n",
      "    (218): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (219): ReLU(inplace=True)\n",
      "    (220): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (221): ReLU(inplace=True)\n",
      "    (222): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (223): ReLU(inplace=True)\n",
      "    (224): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (225): ReLU(inplace=True)\n",
      "    (226): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (227): ReLU(inplace=True)\n",
      "    (228): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (229): ReLU(inplace=True)\n",
      "    (230): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (231): ReLU(inplace=True)\n",
      "    (232): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (233): ReLU(inplace=True)\n",
      "    (234): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (235): ReLU(inplace=True)\n",
      "    (236): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (237): ReLU(inplace=True)\n",
      "    (238): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (239): ReLU(inplace=True)\n",
      "    (240): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (241): ReLU(inplace=True)\n",
      "    (242): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (243): ReLU(inplace=True)\n",
      "    (244): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (245): ReLU(inplace=True)\n",
      "    (246): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (247): ReLU(inplace=True)\n",
      "    (248): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (249): ReLU(inplace=True)\n",
      "    (250): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (251): ReLU(inplace=True)\n",
      "    (252): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (253): ReLU(inplace=True)\n",
      "    (254): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (255): ReLU(inplace=True)\n",
      "    (256): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (257): ReLU(inplace=True)\n",
      "    (258): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (259): ReLU(inplace=True)\n",
      "    (260): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (261): ReLU(inplace=True)\n",
      "    (262): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (263): ReLU(inplace=True)\n",
      "    (264): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (265): ReLU(inplace=True)\n",
      "    (266): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (267): ReLU(inplace=True)\n",
      "    (268): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (269): ReLU(inplace=True)\n",
      "    (270): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (271): ReLU(inplace=True)\n",
      "    (272): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (273): ReLU(inplace=True)\n",
      "    (274): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (275): ReLU(inplace=True)\n",
      "    (276): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (277): ReLU(inplace=True)\n",
      "    (278): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (279): ReLU(inplace=True)\n",
      "    (280): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (281): ReLU(inplace=True)\n",
      "    (282): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (283): ReLU(inplace=True)\n",
      "    (284): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (285): ReLU(inplace=True)\n",
      "    (286): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (287): ReLU(inplace=True)\n",
      "    (288): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (289): ReLU(inplace=True)\n",
      "    (290): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (291): ReLU(inplace=True)\n",
      "    (292): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (293): ReLU(inplace=True)\n",
      "    (294): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (295): ReLU(inplace=True)\n",
      "    (296): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (297): ReLU(inplace=True)\n",
      "    (298): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (299): ReLU(inplace=True)\n",
      "    (300): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (301): ReLU(inplace=True)\n",
      "    (302): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (303): ReLU(inplace=True)\n",
      "    (304): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (305): ReLU(inplace=True)\n",
      "    (306): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (307): ReLU(inplace=True)\n",
      "    (308): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (309): ReLU(inplace=True)\n",
      "    (310): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (311): ReLU(inplace=True)\n",
      "    (312): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (313): ReLU(inplace=True)\n",
      "    (314): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (315): ReLU(inplace=True)\n",
      "    (316): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (317): ReLU(inplace=True)\n",
      "    (318): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (319): ReLU(inplace=True)\n",
      "    (320): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (321): ReLU(inplace=True)\n",
      "    (322): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (323): ReLU(inplace=True)\n",
      "    (324): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (325): ReLU(inplace=True)\n",
      "    (326): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (327): ReLU(inplace=True)\n",
      "    (328): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (329): ReLU(inplace=True)\n",
      "    (330): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (331): ReLU(inplace=True)\n",
      "    (332): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (333): ReLU(inplace=True)\n",
      "    (334): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (335): ReLU(inplace=True)\n",
      "    (336): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (337): ReLU(inplace=True)\n",
      "    (338): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (339): ReLU(inplace=True)\n",
      "    (340): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (341): ReLU(inplace=True)\n",
      "    (342): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (343): ReLU(inplace=True)\n",
      "    (344): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (345): ReLU(inplace=True)\n",
      "    (346): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (347): ReLU(inplace=True)\n",
      "    (348): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (349): ReLU(inplace=True)\n",
      "    (350): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (351): ReLU(inplace=True)\n",
      "    (352): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (353): ReLU(inplace=True)\n",
      "    (354): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (355): ReLU(inplace=True)\n",
      "    (356): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (357): ReLU(inplace=True)\n",
      "    (358): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (359): ReLU(inplace=True)\n",
      "    (360): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (361): ReLU(inplace=True)\n",
      "    (362): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (363): ReLU(inplace=True)\n",
      "    (364): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (365): ReLU(inplace=True)\n",
      "    (366): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (367): ReLU(inplace=True)\n",
      "    (368): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (369): ReLU(inplace=True)\n",
      "    (370): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (371): ReLU(inplace=True)\n",
      "    (372): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (373): ReLU(inplace=True)\n",
      "    (374): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (375): ReLU(inplace=True)\n",
      "    (376): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (377): ReLU(inplace=True)\n",
      "    (378): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (379): ReLU(inplace=True)\n",
      "    (380): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (381): ReLU(inplace=True)\n",
      "    (382): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (383): ReLU(inplace=True)\n",
      "    (384): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (385): ReLU(inplace=True)\n",
      "    (386): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (387): ReLU(inplace=True)\n",
      "    (388): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (389): ReLU(inplace=True)\n",
      "    (390): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (391): ReLU(inplace=True)\n",
      "    (392): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (393): ReLU(inplace=True)\n",
      "    (394): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (395): ReLU(inplace=True)\n",
      "    (396): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (397): ReLU(inplace=True)\n",
      "    (398): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (399): ReLU(inplace=True)\n",
      "    (400): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (401): ReLU(inplace=True)\n",
      "    (402): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (403): ReLU(inplace=True)\n",
      "    (404): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (405): ReLU(inplace=True)\n",
      "    (406): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (407): ReLU(inplace=True)\n",
      "    (408): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (409): ReLU(inplace=True)\n",
      "    (410): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (411): ReLU(inplace=True)\n",
      "    (412): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (413): ReLU(inplace=True)\n",
      "    (414): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (415): ReLU(inplace=True)\n",
      "    (416): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (417): ReLU(inplace=True)\n",
      "    (418): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (419): ReLU(inplace=True)\n",
      "    (420): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (421): ReLU(inplace=True)\n",
      "    (422): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (423): ReLU(inplace=True)\n",
      "    (424): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (425): ReLU(inplace=True)\n",
      "    (426): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (427): ReLU(inplace=True)\n",
      "    (428): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (429): ReLU(inplace=True)\n",
      "    (430): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (431): ReLU(inplace=True)\n",
      "    (432): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (433): ReLU(inplace=True)\n",
      "    (434): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (435): ReLU(inplace=True)\n",
      "    (436): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (437): ReLU(inplace=True)\n",
      "    (438): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (439): ReLU(inplace=True)\n",
      "    (440): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (441): ReLU(inplace=True)\n",
      "    (442): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (443): ReLU(inplace=True)\n",
      "    (444): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (445): ReLU(inplace=True)\n",
      "    (446): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (447): ReLU(inplace=True)\n",
      "    (448): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (449): ReLU(inplace=True)\n",
      "    (450): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (451): ReLU(inplace=True)\n",
      "    (452): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (453): ReLU(inplace=True)\n",
      "    (454): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (455): ReLU(inplace=True)\n",
      "    (456): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (457): ReLU(inplace=True)\n",
      "    (458): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (459): ReLU(inplace=True)\n",
      "    (460): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (461): ReLU(inplace=True)\n",
      "    (462): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (463): ReLU(inplace=True)\n",
      "    (464): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (465): ReLU(inplace=True)\n",
      "    (466): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (467): ReLU(inplace=True)\n",
      "    (468): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (469): ReLU(inplace=True)\n",
      "    (470): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (471): ReLU(inplace=True)\n",
      "    (472): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (473): ReLU(inplace=True)\n",
      "    (474): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (475): ReLU(inplace=True)\n",
      "    (476): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (477): ReLU(inplace=True)\n",
      "    (478): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (479): ReLU(inplace=True)\n",
      "    (480): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (481): ReLU(inplace=True)\n",
      "    (482): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (483): ReLU(inplace=True)\n",
      "    (484): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (485): ReLU(inplace=True)\n",
      "    (486): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (487): ReLU(inplace=True)\n",
      "    (488): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (489): ReLU(inplace=True)\n",
      "    (490): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (491): ReLU(inplace=True)\n",
      "    (492): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (493): ReLU(inplace=True)\n",
      "    (494): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (495): ReLU(inplace=True)\n",
      "    (496): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (497): ReLU(inplace=True)\n",
      "    (498): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (499): ReLU(inplace=True)\n",
      "    (500): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (501): ReLU(inplace=True)\n",
      "    (502): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (503): ReLU(inplace=True)\n",
      "    (504): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (505): ReLU(inplace=True)\n",
      "    (506): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (507): ReLU(inplace=True)\n",
      "    (508): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (509): ReLU(inplace=True)\n",
      "    (510): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (511): ReLU(inplace=True)\n",
      "    (512): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (513): ReLU(inplace=True)\n",
      "    (514): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (515): ReLU(inplace=True)\n",
      "    (516): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (517): ReLU(inplace=True)\n",
      "    (518): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (519): ReLU(inplace=True)\n",
      "    (520): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (521): ReLU(inplace=True)\n",
      "    (522): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (523): ReLU(inplace=True)\n",
      "    (524): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (525): ReLU(inplace=True)\n",
      "    (526): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (527): ReLU(inplace=True)\n",
      "    (528): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (529): ReLU(inplace=True)\n",
      "    (530): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (531): ReLU(inplace=True)\n",
      "    (532): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (533): ReLU(inplace=True)\n",
      "    (534): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (535): ReLU(inplace=True)\n",
      "    (536): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (537): ReLU(inplace=True)\n",
      "    (538): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (539): ReLU(inplace=True)\n",
      "    (540): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (541): ReLU(inplace=True)\n",
      "    (542): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (543): ReLU(inplace=True)\n",
      "    (544): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (545): ReLU(inplace=True)\n",
      "    (546): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (547): ReLU(inplace=True)\n",
      "    (548): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (549): ReLU(inplace=True)\n",
      "    (550): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (551): ReLU(inplace=True)\n",
      "    (552): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (553): ReLU(inplace=True)\n",
      "    (554): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (555): ReLU(inplace=True)\n",
      "    (556): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (557): ReLU(inplace=True)\n",
      "    (558): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (559): ReLU(inplace=True)\n",
      "    (560): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (561): ReLU(inplace=True)\n",
      "    (562): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (563): ReLU(inplace=True)\n",
      "    (564): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (565): ReLU(inplace=True)\n",
      "    (566): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (567): ReLU(inplace=True)\n",
      "    (568): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (569): ReLU(inplace=True)\n",
      "    (570): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (571): ReLU(inplace=True)\n",
      "    (572): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (573): ReLU(inplace=True)\n",
      "    (574): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (575): ReLU(inplace=True)\n",
      "    (576): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (577): ReLU(inplace=True)\n",
      "    (578): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (579): ReLU(inplace=True)\n",
      "    (580): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (581): ReLU(inplace=True)\n",
      "    (582): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (583): ReLU(inplace=True)\n",
      "    (584): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (585): ReLU(inplace=True)\n",
      "    (586): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (587): ReLU(inplace=True)\n",
      "    (588): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (589): ReLU(inplace=True)\n",
      "    (590): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (591): ReLU(inplace=True)\n",
      "    (592): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (593): ReLU(inplace=True)\n",
      "    (594): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (595): ReLU(inplace=True)\n",
      "    (596): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (597): ReLU(inplace=True)\n",
      "    (598): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (599): ReLU(inplace=True)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (fc5): Linear(in_features=512, out_features=14, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "train_loss : 279.829402923584\n",
      "val_loss : 34.23571968078613\n",
      "\n",
      "\n",
      "epoch:1\n",
      "train_loss : 170.71406888961792\n",
      "val_loss : 9.123870372772217\n",
      "\n",
      "\n",
      "epoch:2\n",
      "train_loss : 42.128963232040405\n",
      "val_loss : 3.7899526357650757\n",
      "\n",
      "\n",
      "epoch:3\n",
      "train_loss : 28.612062454223633\n",
      "val_loss : 3.3828247785568237\n",
      "\n",
      "\n",
      "epoch:4\n",
      "train_loss : 25.65065908432007\n",
      "val_loss : 3.0818779468536377\n",
      "\n",
      "\n",
      "epoch:5\n",
      "train_loss : 24.488911032676697\n",
      "val_loss : 2.991361618041992\n",
      "\n",
      "\n",
      "epoch:6\n",
      "train_loss : 23.750900626182556\n",
      "val_loss : 2.912130117416382\n",
      "\n",
      "\n",
      "epoch:7\n",
      "train_loss : 23.213498950004578\n",
      "val_loss : 2.883626341819763\n",
      "\n",
      "\n",
      "epoch:8\n",
      "train_loss : 22.76290464401245\n",
      "val_loss : 2.8145865201950073\n",
      "\n",
      "\n",
      "epoch:9\n",
      "train_loss : 22.265307068824768\n",
      "val_loss : 2.730901837348938\n",
      "\n",
      "\n",
      "epoch:10\n",
      "train_loss : 21.72695541381836\n",
      "val_loss : 2.6828659772872925\n",
      "\n",
      "\n",
      "epoch:11\n",
      "train_loss : 21.298901319503784\n",
      "val_loss : 2.629786729812622\n",
      "\n",
      "\n",
      "epoch:12\n",
      "train_loss : 20.9010488986969\n",
      "val_loss : 2.5688050985336304\n",
      "\n",
      "\n",
      "epoch:13\n",
      "train_loss : 20.609336972236633\n",
      "val_loss : 2.5519174337387085\n",
      "\n",
      "\n",
      "epoch:14\n",
      "train_loss : 20.282220721244812\n",
      "val_loss : 2.521886706352234\n",
      "\n",
      "\n",
      "epoch:15\n",
      "train_loss : 20.072673559188843\n",
      "val_loss : 2.4607009887695312\n",
      "\n",
      "\n",
      "epoch:16\n",
      "train_loss : 19.683616757392883\n",
      "val_loss : 2.4419643878936768\n",
      "\n",
      "\n",
      "epoch:17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10383/3802906485.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch:{epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mval_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# gc.collect()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10383/3802906485.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_batch, criterion, optimizer, train_X, train_Y, device)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train_loss : {train_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.container import Sequential\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "\n",
    "class CFG:\n",
    "    dataPath = \"./open/\"\n",
    "    trainPath = dataPath+'train.csv'\n",
    "    testPath = dataPath+'test.csv'\n",
    "    submission = dataPath+'sample_submission.csv'\n",
    "    outPath = dataPath+'processed/'\n",
    "    weightsavePath = dataPath+'weights/'\n",
    "    \n",
    "    device = 'cuda'\n",
    "    \n",
    "def seedEverything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    np.random.seed(random_seed)    \n",
    "    # np.random.seed(random_seed)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(56, 512)\n",
    "        self.layer1 = self.make_layers(512, num_repeat=300)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc5 = nn.Linear(512, 14)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Dropout(0.2)(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, value, num_repeat):\n",
    "        layers = []\n",
    "        for _ in range(num_repeat):\n",
    "            layers.append(nn.Linear(value, value))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def numpy_to_tensor(variable):\n",
    "    x = variable.values\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "def pandas_to_tensor(variable):\n",
    "    return torch.tensor(variable.values)\n",
    "\n",
    "def train_one_epoch(model, train_batch, criterion, optimizer, train_X, train_Y, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i in range(train_batch):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        input = train_X[start:end].to(device, dtype=torch.float)\n",
    "        label = train_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        outputs = model(input).squeeze()\n",
    "        loss = criterion(outputs, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f\"train_loss : {train_loss}\")\n",
    "    \n",
    "def val_one_epoch(model, val_batch, criterion, val_X, val_Y, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i in range(val_batch):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            input = val_X[start:end].to(device, dtype=torch.float)\n",
    "            label = val_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "            input, label = input.to(device), label.to(device)\n",
    "            outputs = model(input).squeeze()\n",
    "            loss = criterion(outputs, label)\n",
    "            val_loss += loss.item()\n",
    "    print(f\"val_loss : {val_loss}\")\n",
    "    \n",
    "def datapreparation(train_df):\n",
    "    # shuffle\n",
    "    valset_ratio = 0.15\n",
    "    train_df = train_df.sample(frac=1)\n",
    "\n",
    "    train_df_X = train_df.filter(regex='X')\n",
    "    train_df_Y = train_df.filter(regex='Y')\n",
    "\n",
    "    valset_num = round(len(train_df_Y)*valset_ratio)\n",
    "\n",
    "    val_df_X = pandas_to_tensor(train_df_X.iloc[:valset_num])\n",
    "    val_df_Y = pandas_to_tensor(train_df_Y.iloc[:valset_num])    \n",
    "    train_df_X = pandas_to_tensor(train_df_X.iloc[valset_num:])\n",
    "    train_df_Y = pandas_to_tensor(train_df_Y.iloc[valset_num:])\n",
    "\n",
    "    return train_df_X, train_df_Y, val_df_X, val_df_Y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seedEverything(42)\n",
    "    train_df = pd.read_csv(CFG.trainPath)    \n",
    "    train_df_X, train_df_Y, val_df_X, val_df_Y = datapreparation(train_df)\n",
    "\n",
    "    model = NeuralNet()\n",
    "    print(model)\n",
    "    model = model.to(CFG.device)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=3e-4)\n",
    "    criterion = nn.L1Loss().cuda()\n",
    "\n",
    "    num_epochs = 300\n",
    "    batch_size = 2048\n",
    "    \n",
    "    train_batch = len(train_df_X) // batch_size\n",
    "    val_batch = len(val_df_X) // batch_size\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"epoch:{epoch}\")\n",
    "        train_one_epoch(model, train_batch, criterion, optimizer, train_df_X, train_df_Y, CFG.device)\n",
    "        val_one_epoch(model, val_batch, criterion, val_df_X, val_df_Y, CFG.device)\n",
    "        # gc.collect()\n",
    "#         torch.save(model.state_dict(), CFG.weightsavePath+f'{epoch}_neuralnet.pt')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7a32f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7431e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    dataPath = \"./open/\"\n",
    "    trainPath = dataPath+'train.csv'\n",
    "    testPath = dataPath+'test.csv'\n",
    "    submission = dataPath+'sample_submission.csv'\n",
    "    outPath = './output/'\n",
    "    weightsavePath = './weights/'\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3f3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seedEverything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "#     torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    np.random.seed(random_seed)    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d4016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_df = pd.read_csv(CFG.trainPath)\n",
    "train_df, val_df = train_test_split(data_df,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c112ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def numpy_to_tensor(variable):\n",
    "    x = variable.values\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, is_test=False):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        label = self.df.filter(regex='Y')\n",
    "        input_data = self.df.filter(regex='X')\n",
    "        if is_test == True:\n",
    "            return numpy_to_tensor(input_data)\n",
    "        return numpy_to_tensor(input_data), numpy_to_tensor(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb6debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_set = CustomDataset(df=train_df)\n",
    "val_set = CustomDataset(df=val_df)\n",
    "\n",
    "loader_train = DataLoader(dataset=train_set,batch_size=1024,shuffle=True)\n",
    "loader_val = DataLoader(dataset=val_set,batch_size=1024,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72a67b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(56, 512)\n",
    "        self.layer1 = self.make_layers(512, num_repeat=300)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc5 = nn.Linear(512, 14)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Dropout(0.2)(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, value, num_repeat):\n",
    "        layers = []\n",
    "        for _ in range(num_repeat):\n",
    "            layers.append(nn.Linear(value, value))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_batch, criterion, optimizer, train_X, train_Y, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i in range(train_batch):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        input = train_X[start:end].to(device, dtype=torch.float)\n",
    "        label = train_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        outputs = model(input).squeeze()\n",
    "        loss = criterion(outputs, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f\"train_loss : {train_loss}\")\n",
    "    \n",
    "def val_one_epoch(model, val_batch, criterion, val_X, val_Y, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i in range(val_batch):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            input = val_X[start:end].to(device, dtype=torch.float)\n",
    "            label = val_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "            input, label = input.to(device), label.to(device)\n",
    "            outputs = model(input).squeeze()\n",
    "            loss = criterion(outputs, label)\n",
    "            val_loss += loss.item()\n",
    "    print(f\"val_loss : {val_loss}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef91e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456b6d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_04</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>X_10</th>\n",
       "      <th>...</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "      <th>X_51</th>\n",
       "      <th>X_52</th>\n",
       "      <th>X_53</th>\n",
       "      <th>X_54</th>\n",
       "      <th>X_55</th>\n",
       "      <th>X_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.504</td>\n",
       "      <td>103.321</td>\n",
       "      <td>76.67</td>\n",
       "      <td>1</td>\n",
       "      <td>101.867</td>\n",
       "      <td>73.963</td>\n",
       "      <td>30.51</td>\n",
       "      <td>63.57</td>\n",
       "      <td>239.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17227.63</td>\n",
       "      <td>138.130429</td>\n",
       "      <td>129.460682</td>\n",
       "      <td>141.506570</td>\n",
       "      <td>133.427229</td>\n",
       "      <td>129.711498</td>\n",
       "      <td>133.138096</td>\n",
       "      <td>121.859684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.485</td>\n",
       "      <td>103.320</td>\n",
       "      <td>69.37</td>\n",
       "      <td>1</td>\n",
       "      <td>101.992</td>\n",
       "      <td>67.845</td>\n",
       "      <td>28.03</td>\n",
       "      <td>116.99</td>\n",
       "      <td>189.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17134.53</td>\n",
       "      <td>136.148839</td>\n",
       "      <td>128.266277</td>\n",
       "      <td>145.911745</td>\n",
       "      <td>131.196417</td>\n",
       "      <td>132.411480</td>\n",
       "      <td>133.629025</td>\n",
       "      <td>124.178623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>68.97</td>\n",
       "      <td>1</td>\n",
       "      <td>101.884</td>\n",
       "      <td>77.022</td>\n",
       "      <td>29.65</td>\n",
       "      <td>205.68</td>\n",
       "      <td>214.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14860.83</td>\n",
       "      <td>120.447446</td>\n",
       "      <td>119.988804</td>\n",
       "      <td>132.099908</td>\n",
       "      <td>120.450155</td>\n",
       "      <td>130.051708</td>\n",
       "      <td>128.252972</td>\n",
       "      <td>114.475628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>65.87</td>\n",
       "      <td>1</td>\n",
       "      <td>101.866</td>\n",
       "      <td>73.963</td>\n",
       "      <td>28.15</td>\n",
       "      <td>103.38</td>\n",
       "      <td>180.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15252.53</td>\n",
       "      <td>133.994695</td>\n",
       "      <td>125.069180</td>\n",
       "      <td>147.507669</td>\n",
       "      <td>123.142653</td>\n",
       "      <td>125.963665</td>\n",
       "      <td>139.666592</td>\n",
       "      <td>126.589253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.603</td>\n",
       "      <td>103.321</td>\n",
       "      <td>66.67</td>\n",
       "      <td>1</td>\n",
       "      <td>101.891</td>\n",
       "      <td>74.983</td>\n",
       "      <td>29.92</td>\n",
       "      <td>71.20</td>\n",
       "      <td>231.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10752.23</td>\n",
       "      <td>137.918202</td>\n",
       "      <td>135.116192</td>\n",
       "      <td>138.600473</td>\n",
       "      <td>127.173033</td>\n",
       "      <td>137.252712</td>\n",
       "      <td>134.411335</td>\n",
       "      <td>124.020016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39603</th>\n",
       "      <td>68.504</td>\n",
       "      <td>103.320</td>\n",
       "      <td>63.97</td>\n",
       "      <td>1</td>\n",
       "      <td>103.157</td>\n",
       "      <td>68.864</td>\n",
       "      <td>29.49</td>\n",
       "      <td>116.35</td>\n",
       "      <td>284.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62123.53</td>\n",
       "      <td>127.741246</td>\n",
       "      <td>126.494312</td>\n",
       "      <td>139.119905</td>\n",
       "      <td>125.271109</td>\n",
       "      <td>128.284572</td>\n",
       "      <td>140.176945</td>\n",
       "      <td>128.292843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39604</th>\n",
       "      <td>68.504</td>\n",
       "      <td>103.320</td>\n",
       "      <td>61.37</td>\n",
       "      <td>1</td>\n",
       "      <td>103.137</td>\n",
       "      <td>68.864</td>\n",
       "      <td>32.29</td>\n",
       "      <td>116.28</td>\n",
       "      <td>272.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61844.13</td>\n",
       "      <td>127.767377</td>\n",
       "      <td>124.062809</td>\n",
       "      <td>138.238664</td>\n",
       "      <td>119.879393</td>\n",
       "      <td>127.322529</td>\n",
       "      <td>137.312047</td>\n",
       "      <td>131.570614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39605</th>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>63.67</td>\n",
       "      <td>1</td>\n",
       "      <td>103.149</td>\n",
       "      <td>69.884</td>\n",
       "      <td>30.00</td>\n",
       "      <td>113.05</td>\n",
       "      <td>295.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60277.53</td>\n",
       "      <td>128.593640</td>\n",
       "      <td>124.774037</td>\n",
       "      <td>138.659624</td>\n",
       "      <td>123.999571</td>\n",
       "      <td>126.075542</td>\n",
       "      <td>135.656132</td>\n",
       "      <td>127.671108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39606</th>\n",
       "      <td>67.485</td>\n",
       "      <td>103.321</td>\n",
       "      <td>61.77</td>\n",
       "      <td>1</td>\n",
       "      <td>103.148</td>\n",
       "      <td>67.845</td>\n",
       "      <td>32.05</td>\n",
       "      <td>115.05</td>\n",
       "      <td>267.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60236.73</td>\n",
       "      <td>121.110646</td>\n",
       "      <td>125.471699</td>\n",
       "      <td>134.989984</td>\n",
       "      <td>120.889578</td>\n",
       "      <td>129.296909</td>\n",
       "      <td>132.673977</td>\n",
       "      <td>131.882893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39607</th>\n",
       "      <td>71.563</td>\n",
       "      <td>103.320</td>\n",
       "      <td>63.07</td>\n",
       "      <td>1</td>\n",
       "      <td>103.158</td>\n",
       "      <td>71.923</td>\n",
       "      <td>31.14</td>\n",
       "      <td>102.22</td>\n",
       "      <td>215.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60680.73</td>\n",
       "      <td>134.263593</td>\n",
       "      <td>129.765515</td>\n",
       "      <td>139.681833</td>\n",
       "      <td>128.243391</td>\n",
       "      <td>131.757923</td>\n",
       "      <td>139.903401</td>\n",
       "      <td>121.479191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39608 rows  56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08    X_09  \\\n",
       "0      68.504  103.321  76.67     1  101.867  73.963  30.51   63.57  239.80   \n",
       "1      67.485  103.320  69.37     1  101.992  67.845  28.03  116.99  189.23   \n",
       "2      69.524  103.320  68.97     1  101.884  77.022  29.65  205.68  214.93   \n",
       "3      69.524  103.320  65.87     1  101.866  73.963  28.15  103.38  180.80   \n",
       "4      73.603  103.321  66.67     1  101.891  74.983  29.92   71.20  231.93   \n",
       "...       ...      ...    ...   ...      ...     ...    ...     ...     ...   \n",
       "39603  68.504  103.320  63.97     1  103.157  68.864  29.49  116.35  284.16   \n",
       "39604  68.504  103.320  61.37     1  103.137  68.864  32.29  116.28  272.41   \n",
       "39605  69.524  103.320  63.67     1  103.149  69.884  30.00  113.05  295.54   \n",
       "39606  67.485  103.321  61.77     1  103.148  67.845  32.05  115.05  267.26   \n",
       "39607  71.563  103.320  63.07     1  103.158  71.923  31.14  102.22  215.85   \n",
       "\n",
       "       X_10  ...  X_47  X_48      X_49        X_50        X_51        X_52  \\\n",
       "0       0.0  ...     1     1  17227.63  138.130429  129.460682  141.506570   \n",
       "1       0.0  ...     1     1  17134.53  136.148839  128.266277  145.911745   \n",
       "2       0.0  ...     1     1  14860.83  120.447446  119.988804  132.099908   \n",
       "3       0.0  ...     1     1  15252.53  133.994695  125.069180  147.507669   \n",
       "4       0.0  ...     1     1  10752.23  137.918202  135.116192  138.600473   \n",
       "...     ...  ...   ...   ...       ...         ...         ...         ...   \n",
       "39603   0.0  ...     1     1  62123.53  127.741246  126.494312  139.119905   \n",
       "39604   0.0  ...     1     1  61844.13  127.767377  124.062809  138.238664   \n",
       "39605   0.0  ...     1     1  60277.53  128.593640  124.774037  138.659624   \n",
       "39606   0.0  ...     1     1  60236.73  121.110646  125.471699  134.989984   \n",
       "39607   0.0  ...     1     1  60680.73  134.263593  129.765515  139.681833   \n",
       "\n",
       "             X_53        X_54        X_55        X_56  \n",
       "0      133.427229  129.711498  133.138096  121.859684  \n",
       "1      131.196417  132.411480  133.629025  124.178623  \n",
       "2      120.450155  130.051708  128.252972  114.475628  \n",
       "3      123.142653  125.963665  139.666592  126.589253  \n",
       "4      127.173033  137.252712  134.411335  124.020016  \n",
       "...           ...         ...         ...         ...  \n",
       "39603  125.271109  128.284572  140.176945  128.292843  \n",
       "39604  119.879393  127.322529  137.312047  131.570614  \n",
       "39605  123.999571  126.075542  135.656132  127.671108  \n",
       "39606  120.889578  129.296909  132.673977  131.882893  \n",
       "39607  128.243391  131.757923  139.903401  121.479191  \n",
       "\n",
       "[39608 rows x 56 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(CFG.testPath)\n",
    "test_df_XX = test_df.filter(regex='X')\n",
    "# test_df_X = pandas_to_tensor(test_df.iloc[:])\n",
    "test_df_XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deaad83e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas_to_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2215412/950834199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df_XX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas_to_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = pandas_to_tensor(test_df_XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    seedEverything(42)\n",
    "    train_df = pd.read_csv(CFG.trainPath)    \n",
    "    train_df_X, train_df_Y, val_df_X, val_df_Y = datapreparation(train_df)\n",
    "\n",
    "    model = NeuralNet()\n",
    "    model = model.to(CFG.device)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=3e-4)\n",
    "    criterion = nn.L1Loss().cuda()\n",
    "\n",
    "    num_epochs = 300\n",
    "    batch_size = 2048\n",
    "    \n",
    "    train_batch = len(train_df_X) // batch_size\n",
    "    val_batch = len(val_df_X) // batch_size\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"epoch:{epoch}\")\n",
    "        train_one_epoch(model, train_batch, criterion, optimizer, train_df_X, train_df_Y, CFG.device)\n",
    "        val_one_epoch(model, val_batch, criterion, val_df_X, val_df_Y, CFG.device)\n",
    "        # gc.collect()\n",
    "        torch.save(model.state_dict(), CFG.weightsavePath+f'{epoch}_neuralnet.pt')\n",
    "        print('\\n')\n",
    "#https://wooono.tistory.com/102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdcf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, test_loader, device):\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "#     model_preds = []\n",
    "#     with torch.no_grad():\n",
    "#         for data in tqdm(iter(test_loader)):\n",
    "#             data = data.float().to(device)\n",
    "            \n",
    "#             batch_pred = model(data)\n",
    "            \n",
    "#             model_preds += batch_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "#     return model_preds\n",
    "\n",
    "test_batch = len(test_df_XX) // batch_size\n",
    "model.eval()\n",
    "preds=[]\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    for i in range(test_batch+1):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        print(end)\n",
    "        if end>len(test_data):\n",
    "#             print(\"check\")\n",
    "            end = len(test_data)\n",
    "            \n",
    "        input = test_data[start:end].to(device, dtype=torch.float)\n",
    "#         label = val_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "        input= input.to(device)\n",
    "        outputs = model(input).squeeze()\n",
    "#         print(outputs)\n",
    "        preds += outputs.detach().cpu().numpy().tolist()\n",
    "#         preds.append(outputs\n",
    "#         loss = criterion(outputs, label)\n",
    "#         val_loss += loss.item()\n",
    "# print(f\"val_loss : {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc008d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds\n",
    "preds_np=np.array(preds)\n",
    "preds_np.shape\n",
    "\n",
    "# preds_np = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e156886",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(CFG.submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f282bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7337c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a90162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(n_models):\n",
    "  all_models=list()\n",
    "  for i in range(n_models):\n",
    "    filename='/content/drive/MyDrive/lg aimers/models/'+str(i+1)+'.h5'\n",
    "    model=load_model(filename)\n",
    "    all_models.append(model)\n",
    "\n",
    "    print('>loaded %s' %filename)\n",
    "  return all_models\n",
    "  \n",
    "def define_stacked_model(members):\n",
    "  # update all layers in all models to not be trainiable\n",
    "  for i in range(len(members)):\n",
    "    model=members[i]\n",
    "    for layer in model.layers:\n",
    "      layer.trainable=False\n",
    "      # rename to avoid 'unique layer name' issue\n",
    "      layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "  \n",
    "  # define multi-handed input\n",
    "  ensemble_visible=[model.input for model in members]\n",
    "  ensemble_outputs=[model.output for model in members]\n",
    "\n",
    "  y=Average()(ensemble_outputs)\n",
    "\n",
    "  model=Model(inputs=ensemble_visible,outputs=y,name='ensemble')\n",
    "\n",
    "  keras.utils.plot_model(model,show_shapes=True,to_file='/content/drive/MyDrive/lg aimers/model_graph.jpg')\n",
    "\n",
    "  model.compile(loss='mae',optimizer='adam')\n",
    "  return model\n",
    "\n",
    "def fit_stacked_model(model,trainX,valX,trainY,valY):\n",
    "  x_train=[trainX for _ in range(len(model.input))]\n",
    "  x_val=[valX for _ in range(len(model.input))]\n",
    "  y_train=trainY\n",
    "  y_val=valY\n",
    "\n",
    "  es=keras.callbacks.EarlyStopping(monitor='val_loss',patience=20)\n",
    "  checkpoint_filepath='/content/drive/MyDrive/lg aimers/ensemble_model.h5'\n",
    "  cp=keras.callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      monitor='val_loss',\n",
    "      save_best_only=True\n",
    "  )\n",
    "  model.fit(x_train,y_train,epochs=1,validation_data=(x_val,y_val),callbacks=[es,cp],batch_size=32)\n",
    "\n",
    "def evaluate_stacked_model(model,inputX,y_val):\n",
    "  x_val=[inputX for _ in range(len(model.input))]\n",
    "  return model.evaluate(x_val,y_val)\n",
    "\n",
    "def predict_stacked_model(model,inputX):\n",
    "  x_test=[inputX for _ in range(len(model.input))]\n",
    "  return model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95183fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_members=5\n",
    "members=load_all_models(n_members)\n",
    "print('Loaded %d members' %len(members))\n",
    "\n",
    "stacked_model=define_stacked_model(members)\n",
    "fit_stacked_model(stacked_model,x_train,x_val,y_train,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_stacked_model(stacked_model,x_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=predict_stacked_model(stacked_model,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e733fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pd=pd.read_csv('/content/drive/MyDrive/lg aimers/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf812a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,col in enumerate(submission_pd.columns):\n",
    "  if col=='ID':\n",
    "    continue\n",
    "  submission_pd[col]=result[:,idx-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pd.to_csv('/content/drive/MyDrive/lg aimers/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
